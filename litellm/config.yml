# https://artificialanalysis.ai/models
# https://chat.lmsys.org/?leaderboard
allow_origins: ["https://*.madpin.dev", "http://*.madpin.dev"]
# Include credentials first, then all model configurations from separate files
include:
  - models/credentials.yml
  - models/embeddings.yml
  # Model families (organized by model type rather than provider)
  - models/openai_gpt.yml
  - models/openai_o.yml
  - models/claude.yml
  - models/gemini.yml
  - models/llama.yml
  - models/qwen.yml
  - models/grok.yml
  - models/deepseek.yml
  - models/sonar.yml
  - models/moonshot.yml
  - models/glm.yml

router_settings:
  routing_strategy: simple-shuffle
  redis_url: "os.environ/REDIS_URL"
  enable_pre_call_check: true
  num_retries: 2 # retry call 3 times on each model_name (e.g. translate).
  allowed_fails: 3 # cooldown model if it fails > 1 call in a minute.
  cooldown_time: 300 # cooldown model for 5 minutes if it fails > 1 call in a minute.
  cache_responses: true # cache responses for 5 minutes

  enable_pre_call_checks: true # 1. Enable pre-call checks
  # model_group_alias:
  #   best: gemini-2.0-pro-exp-02-05
  #   good: gemini-2.0-flash
  #   cheap: llama-3.3-70b-versatile
  #   cheapest: llama-3.1-8b-instant
  #   gpt-4o-mini: gpt-4.1-mini
  #   gpt-4o: gpt-4.1
  #   o3-mini-high: o4-mini-high
  #   o3-mini: o4-mini-high



litellm_settings:
  set_verbose: false
  request_timeout: 300 # raise Timeout error if call takes longer than 300s. Sets litellm.request_timeout
  fallbacks: [{ "paraphrase": ["default"] }] # fallback to default model if paraphrase model fails num_retries
  telemetry: False
  drop_params: True # Ignore parameter that the model doesn't understand
  modify_params: True

  # callbacks: ["langfuse", "posthog","logfire",  "datadog_llm_observability"]
  callbacks:
    - langfuse
    - datadog_llm_observability
    - logfire
    # - posthog
  success_callback:
    - posthog
    - langfuse
  # failure_callback: ["langfuse"]
  # For Production:

  # json_logs: True
  cache: True
  cache_params:
    type: redis
    namespace: "litellm.caching.caching"
    redis_url: "os.environ/REDIS_URL"
    # redis_url: "os.environ/REDIS_URL"
    # host: "os.environ/REDIS_HOST"
    # port: os.environ/REDIS_PORT
    # password: "os.environ/REDIS_PASSWORD"

general_settings:
  master_key: "os.environ/LITELLM_MASTER_KEY"
